{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Compression - Homework #4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 8.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     1,
     3,
     9
    ]
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def quantize(x):\n",
    "    return math.ceil(x)-0.5\n",
    "def compand(x):\n",
    "    if x > 1:\n",
    "        return x*2/3 + 4/3\n",
    "    if x < -1:\n",
    "        return x*2/3 - 4/3\n",
    "    return x*2\n",
    "def de_compand(x):\n",
    "    if x > 2:\n",
    "        return x*3/2 - 2\n",
    "    if x < -2:\n",
    "        return x*3/2 + 2\n",
    "    return x/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datas = [-0.8, 1.2, 0.5, 0.6, 3.2, -0.3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantize with compander"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Input |  Companded |  Quantized |   Restruct |       Diff\n",
      "--------------------------------------------------------------\n",
      "    -0.800 |     -1.600 |     -1.500 |     -0.750 |      0.050\n",
      "     1.200 |      2.133 |      2.500 |      1.750 |      0.550\n",
      "     0.500 |      1.000 |      0.500 |      0.250 |     -0.250\n",
      "     0.600 |      1.200 |      1.500 |      0.750 |      0.150\n",
      "     3.200 |      3.467 |      3.500 |      3.250 |      0.050\n",
      "    -0.300 |     -0.600 |     -0.500 |     -0.250 |      0.050\n"
     ]
    }
   ],
   "source": [
    "print(\" | \".join([\"{:>10}\"]*5).format(\"Input\", \"Companded\", \"Quantized\", \"Restruct\", \"Diff\"))\n",
    "print(\"-\"*62)\n",
    "for each in test_datas:\n",
    "    comped = compand(each)\n",
    "    quanted = quantize(comped)\n",
    "    restruct = de_compand(quanted)\n",
    "    diff = restruct - each\n",
    "    print(\" | \".join([\"{:>10.3f}\"]*5).format(each, comped, quanted, restruct, diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantize without compander"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Input |  Quantized |       Diff\n",
      "------------------------------------\n",
      "    -0.800 |     -0.500 |      0.300\n",
      "     1.200 |      1.500 |      0.300\n",
      "     0.500 |      0.500 |      0.000\n",
      "     0.600 |      0.500 |     -0.100\n",
      "     3.200 |      3.500 |      0.300\n",
      "    -0.300 |     -0.500 |     -0.200\n"
     ]
    }
   ],
   "source": [
    "print(\" | \".join([\"{:>10}\"]*3).format(\"Input\", \"Quantized\", \"Diff\"))\n",
    "print(\"-\"*36)\n",
    "for each in test_datas:\n",
    "    quanted = quantize(each)\n",
    "    diff = quanted - each\n",
    "    print(\" | \".join([\"{:>10.3f}\"]*3).format(each, quanted, diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Quantize with compander has significantly reduce the error during the quantizatio. Therefore, designing a compander according to different input distribution is no doubt an important subject to be discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 8.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0,
     7,
     13
    ]
   },
   "outputs": [],
   "source": [
    "def jayant_quantize(x, step_size=0.5, multipliers=[0.8, 0.9, 1, 1.2]):\n",
    "    output_level = int(x//step_size)\n",
    "    output = (output_level+1/2)*step_size\n",
    "    if output_level < 0:\n",
    "        output_level = 3-output_level\n",
    "    new_step_size = step_size * multipliers[output_level%len(multipliers)]\n",
    "    return new_step_size, output\n",
    "def fixed_nonuniform_quantize(x):\n",
    "    intervals = [0.3, 0.6, 1.2, 2]\n",
    "    negative = x<0\n",
    "    for step in intervals:\n",
    "        if abs(x) <= step:\n",
    "            return step if not negative else -step\n",
    "def adaptive_uniform_quantize(x):\n",
    "    # using function defined in problem 8.6\n",
    "    return de_compand(quantize(compand(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datas = [0.1, -0.2, 0.2, 0.1, -0.3, 0.1, 0.2, 0.5, 0.9, 1.5, 1.0, 0.9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jayant Quantizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Input |  Quantized |       Diff\n",
      "------------------------------------\n",
      "     0.100 |      0.250 |      0.150\n",
      "    -0.200 |     -0.200 |      0.000\n",
      "     0.200 |      0.160 |     -0.040\n",
      "     0.100 |      0.128 |      0.028\n",
      "    -0.300 |     -0.307 |     -0.007\n",
      "     0.100 |      0.092 |     -0.008\n",
      "     0.200 |      0.221 |      0.021\n",
      "     0.500 |      0.464 |     -0.036\n",
      "     0.900 |      0.876 |     -0.024\n",
      "     1.500 |      1.505 |      0.005\n",
      "     1.000 |      0.932 |     -0.068\n",
      "     0.900 |      0.932 |      0.032\n"
     ]
    }
   ],
   "source": [
    "print(\" | \".join([\"{:>10}\"]*3).format(\"Input\", \"Quantized\", \"Diff\"))\n",
    "print(\"-\"*36)\n",
    "step_size = 0.5\n",
    "for each in test_datas:\n",
    "    step_size, output = jayant_quantize(each, step_size)\n",
    "    diff = output - each\n",
    "    print(\" | \".join([\"{:>10.3f}\"]*3).format(each, output, diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed Nonuniform Quantizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Input |  Quantized |       Diff\n",
      "------------------------------------\n",
      "     0.100 |      0.300 |      0.200\n",
      "    -0.200 |     -0.300 |     -0.100\n",
      "     0.200 |      0.300 |      0.100\n",
      "     0.100 |      0.300 |      0.200\n",
      "    -0.300 |     -0.300 |      0.000\n",
      "     0.100 |      0.300 |      0.200\n",
      "     0.200 |      0.300 |      0.100\n",
      "     0.500 |      0.600 |      0.100\n",
      "     0.900 |      1.200 |      0.300\n",
      "     1.500 |      2.000 |      0.500\n",
      "     1.000 |      1.200 |      0.200\n",
      "     0.900 |      1.200 |      0.300\n"
     ]
    }
   ],
   "source": [
    "print(\" | \".join([\"{:>10}\"]*3).format(\"Input\", \"Quantized\", \"Diff\"))\n",
    "print(\"-\"*36)\n",
    "for each in test_datas:\n",
    "    output = fixed_nonuniform_quantize(each)\n",
    "    diff = output - each\n",
    "    print(\" | \".join([\"{:>10.3f}\"]*3).format(each, output, diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Uniform Quantizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Input |  Quantized |       Diff\n",
      "------------------------------------\n",
      "     0.100 |      0.250 |      0.150\n",
      "    -0.200 |     -0.250 |     -0.050\n",
      "     0.200 |      0.250 |      0.050\n",
      "     0.100 |      0.250 |      0.150\n",
      "    -0.300 |     -0.250 |      0.050\n",
      "     0.100 |      0.250 |      0.150\n",
      "     0.200 |      0.250 |      0.050\n",
      "     0.500 |      0.250 |     -0.250\n",
      "     0.900 |      0.750 |     -0.150\n",
      "     1.500 |      1.750 |      0.250\n",
      "     1.000 |      0.750 |     -0.250\n",
      "     0.900 |      0.750 |     -0.150\n"
     ]
    }
   ],
   "source": [
    "print(\" | \".join([\"{:>10}\"]*3).format(\"Input\", \"Quantized\", \"Diff\"))\n",
    "print(\"-\"*36)\n",
    "for each in test_datas:\n",
    "    output = adaptive_uniform_quantize(each)\n",
    "    diff = output - each\n",
    "    print(\" | \".join([\"{:>10.3f}\"]*3).format(each, output, diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Using adaptive nonuniform quantizer such as Jayant quantizer can effectively reduce the error during the quantization.\n",
    "We can also achieve similar result with fixed nonuniform quantizer, but the edge case can't perform as good as Jayant quantizer. However, it is apparent that nonuniform quantizer done a better job in error reduction comparing to uniform quantizer, but it is of course, the trade off between system complication and error significent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
